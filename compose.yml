services:
  # 1. Wake-word
  openwakeword:
    image: rhasspy/wyoming-openwakeword
    container_name: wakeword
    command: >
      --preload-model hey_mycroft 
      --preload-model alexa 
      --debug
    ports: ["10400:10400"]
    restart: unless-stopped
    devices:
      - /dev/snd:/dev/snd
    group_add:
      - audio
    volumes: ["./openwake_data:/data"]

  # 2. Speech-to-text - WHISPER
  whisper:
    image: rhasspy/wyoming-whisper
    container_name: whisper
    ports:
      - "10300:10300"
    volumes: ["./whisper_data:/data"]
    command: >
      --model Systran/faster-distil-whisper-small.en
      --debug
    restart: unless-stopped
    devices:
      - /dev/snd:/dev/snd
    group_add:
      - audio
    # GPU Access
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # 3. Large-language model for Intent Check (Local)
  ollama_intent:
    image: ollama/ollama
    container_name: ollama_intent
    ports: ["11434:11434"]
    volumes:
      - ./ollama_intent_data:/root/.ollama
      - ./intent_entrypoint.sh:/entrypoint.sh
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    restart: unless-stopped
    environment:
      - OPT_OUT_CAPTURE=true
    # GPU Access
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KEEP_ALIVE=-1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

   # 4. Large-language model for Chatting (Local)
  ollama_chat:
    image: ollama/ollama
    container_name: ollama_chat
    ports: ["11435:11434"]
    volumes:
      - ./ollama_chat_data:/root/.ollama
      - ./chat_entrypoint.sh:/entrypoint.sh
    entrypoint: ["/bin/bash", "/entrypoint.sh"]
    restart: unless-stopped
    environment:
      - OPT_OUT_CAPTURE=true
    # GPU Access
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_KEEP_ALIVE=-1
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # 5. Text-to-speech - PIPER
  piper:
    image: rhasspy/wyoming-piper
    container_name: piper
    ports: ["10200:10200"]
    devices:
      - /dev/snd:/dev/snd
    group_add:
      - audio
    volumes: ["./piper_data:/data"]
    command: >
      --voice /data/voice/en_GB/en_GB-cori-high.onnx
      --data-dir /data
    restart: unless-stopped
    # GPU Access
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # 6. Web Search - Searxng
  searxng:
    image: searxng/searxng:latest
    container_name: searxng
    ports:
      - "8080:8080"
    volumes:
      - ./searxng_data:/etc/searxng:rw
    restart: unless-stopped
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
      - DAC_OVERRIDE

volumes:
  openwake_data: {}
  whisper_data: {}
  ollama_intent_data: {}
  ollama_chat_data: {}
  piper_data: {} 
  searxng_data: {}